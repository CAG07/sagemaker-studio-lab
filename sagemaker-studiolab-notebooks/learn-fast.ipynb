{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa277843-0bc3-4179-853b-a5b473ad9653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import torch\n",
    "import torchaudio\n",
    "import openai\n",
    "import textwrap\n",
    "import os\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4014652-263f-4ce9-9455-1e8ce3425068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there this is Valentine and welcome to another tutorial this time I wanted to introduce you to get lab CI soget lab continuous integration tool this is built in the get lab tool you do not need to download any software or anything like that all you need is a browser and get lab account it's totally free so if you haven't created an account do that now and once you are logged into your account you should see something like new project here on the right so we're gonna create a very simple project and we are gonna create a continuous integration pipeline it will be very very simple but just to demonstrate the basic functionality of get lab so go ahead click new project and this will be something like my simple pipeline and right here below you have the possibility of selecting the visibility you can make it public if you want but I will leave it private because I'm just playing around so right here below I'm gonna create the project now once that is ready you will have normal repository so there's nothing inside it so the first thing that we'll do is create a new file and this file will be called that it lab - see I got mo so this is how the file should be named and this is a convention it will automatically recognize it so what we're trying to do here is to create two basic stages there will be a build stage and there will be a test stage now in the build stage I will do something very simple I create a file and then in the head stage I will test that that file was actually created in the previous lab so pretty pretty basic now in order to get something to run you need to define some build steps so we are going to define the stages how they are called in gate level so I'm gonna say something like stages column and then with the tap I'm gonna say there's a build stage and there is a test age so these are the stages the two stages that we'll have and now we have to define the jobs themselves so well can I have a build and you can define it as you want so you can name it as you want but it's important now to say that to the stage it's built and the next thing we can really get into coding so we can really define what this stage to do so this will be something like script and now we can just type in something like a hole and I say this is building and the second step will be let's create a new directory called build and let's create a file inside this directory we'll be a simple empty file nothing special and now let's create test job and this will be part of the stage test this is the second taste this is a second stage that we're running and again we'll have a script and in this case we're gonna say something like testing this is just demonstrate that you can enter multiple commands one after the other and we're gonna use the test command and I'm gonna test that this is a file I'm gonna say build in four dot txt okay so now we have this let's commit and see if the syntax that we have here is valid and we're getting this message here that this kid lab configuration is valid and that is actually great news now if we go to the project overview you will see here that something has started to build so this is the icon that it's showing you that the pipeline has started and I didn't need to configure anything in particular just by having this file here and no other files gitlab started building this pipeline as instructed and if I click this icon you will be actually able to see the pipeline how it looks I will see they are two stages and there's the build stage and there's the test stage this is the job name so now right now we're building and this will take a minute to start a docker image and to actually execute us the first stage succeeded and this goes down to the second stage and you will see now the second stage is running as well so let's see if this is successful and I will see that this job actually failed and this is because in the previous job we created some files and after the job completed everything was sort of a thrown away so we need to find a way to make these two separate jobs communicate with one another and the magic word in this case is artifacts we need to define some artifacts so that the first job can create those artifacts and inform the next job or any other job in between to access that those artifacts so we'll have to change a bit our configuration in order to do that and at the build step you will see that after the script we need to add something like artifacts and we're gonna say here that we define some paths where these artifacts should be located and only artifact that we are interested in are inside a build folder so this should probably be enough to publish those artifacts so let's commit those changes again and see now if the pipeline is successful you can also easily see the pipeline's that are currently running if you go on its left panel on click on see ICD pipelines you will see now that this current pipeline is running it's on the first stage and still needs a bit to complete but soon it will get to the second stage and then it should probably be successful and now I just refresh the page and so that both stages are successful and let's go into the test one to see exactly what happened there and you'll see that this command has been displayed here testing and then the test itself that this file exists has worked as well and you'll see here the effect that these artifacts are being downloaded and this makes this entire pipeline work now this is a very very simple pipeline but as you can see you can build upon it and you can really get into more complicated things if you need to thank you for watching this tutorial give it a thumbs up if you think you have learned something new and if you're interested in more detail tutorials make sure you hit the subscribe button because I'll be posting in the next period more tutorials see you next time bye bye you \n"
     ]
    }
   ],
   "source": [
    "# Specify the YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/\" # Add the URL of the YouTube video here\n",
    "\n",
    "# Extract the video ID from the URL using regular expressions\n",
    "match = re.search(r\"v=([A-Za-z0-9_-]+)\", youtube_url)\n",
    "if match:\n",
    "    video_id = match.group(1)\n",
    "else:\n",
    "    raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "# Get the transcript from YouTube\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "# Concatenate the transcript into a single string\n",
    "transcript_text = \"\"\n",
    "for segment in transcript:\n",
    "    transcript_text += segment[\"text\"] + \" \"\n",
    "print(transcript_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bdfc62-1187-464c-a7d2-cf21594c5e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\craig\\Python\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wanted to introduce you to get lab cl so now and once you are logged into your account you should see something like new project here on the right we're gonna sell a very small project and we're on the other side.If you want to make it public if you want but I will leave it prevate because I'm just playing around so right here- See I got mo so this is how the file should be named and this is a condition it will easily reflect it so we're trying to do here is will be a built stage and there will be a test stage now in the building stage I will do something very small I create a file and then in the head stage I will test that file was actually laid in the original stageI'm gonna say something like stickies and then with the tap I'm gonna say there's a built stage and there is a testage so these are the two pages that we'll have and now we have to deal with the jobs themselves so well can I have a built and you can declare it as you can name it as you want but it's important now to sayAt the stage it's built and the next thing we can really get into counting so we can really define what this stage to do so this will be something like crash and now we can just type in something like a hole and I say this is building and the second step will be let's create a new worldwide call and let's create a file inside this distance we'll be a simple operation and now let's new top job and this will be part of the new top test this is the second place this is set is a second place is the next place to be the next.Well, that we're running and again we'll have a story and in this case we're gonna say something like speaking this is just demonstrate that you can enter multicompands after the other and we're gonna use the test company and I'm gonna test that this is a file I'm gonna say built in four times okay so now we have this let's committee and see if the syntax that we have here isTo the project overview you will see here that something has started to build so this is the icon that it's showing you that the pipeline has started and I didn't need to negotiate anything in part just by having this file here and no other files given started building this picture as built and if I Nick this icon will be actually able to see how it looks I will see they are two times and there's the built stage and there's the top shot this is the job named right now nowWell, we're building and this will take a minute to start a docker image and to actually explain us the first stage and this goes down to the second stage and you will see now the second stage is running as well as running as well if this is presentful and I will see that this job actually failed and this is because in the precious job job we created some files and after the job combined everything was sort of a throw away we need to find a way to make these two separate with one another.I'm sorry, d the magic word in this case is artifacts we need to deny some artifacts so that the first job can create those artifacts and inform the next job or any other job in between that those artifs so we'll have to change a bit of our opinion in order to do that and at the build step you will see that after the script we need to add like artifacts and we're gonna say here that we defined some of these objects where these artifacts should be located and only interesting that we are interested inIf you go on its own, then you'll be able to find out what you're talking about, and what you're talking about, and what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about, what you're talking about.And so that both tables are subjectful and let's go into the test one to see exactly what happened there and you'll see that this company has been destroyed here and then the test itself has worked as well and you'll see here that these objects are being downloaded and this makes this entire picture work now is a very simple picture but as you can see you can build onto it and you can really get into more global things if you need to thank you forWatching this tutural give it a tumbles up if you think you have learned something new and if you're interested in more detail tutuaries make sure you hit the subscript because I'll be poking in the next perod more tutuaries see you next time by you\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_length = 512\n",
    "\n",
    "# Split the input text into smaller segments\n",
    "segments = [transcript_text[i:i+max_length] for i in range(0, len(transcript_text), max_length)]\n",
    "\n",
    "# Translate each segment and concatenate the results\n",
    "translated_text = \"\"\n",
    "for segment in segments:\n",
    "    result = translator(segment)\n",
    "    translated_text += result[0]['translation_text']\n",
    "\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50374a98-eab9-488b-8c2e-b8ec32d2d1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# Instantiate the tokenizer and the summarization pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained('stevhliu/my_awesome_billsum_model')\n",
    "summarizer = pipeline(\"summarization\", model='stevhliu/my_awesome_billsum_model', tokenizer=tokenizer)\n",
    "\n",
    "# Define chunk size in number of words\n",
    "chunk_size = 200 # you may need to adjust this value depending on the average length of your words\n",
    "\n",
    "# Split the text into chunks\n",
    "words = transcript_text.split()\n",
    "chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# Summarize each chunk\n",
    "summaries = []\n",
    "for chunk in chunks:\n",
    "    # Summarize the chunk\n",
    "    summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)\n",
    "\n",
    "    # Extract the summary text\n",
    "    summary_text = summary[0]['summary_text']\n",
    "\n",
    "    # Add the summary to our list of summaries\n",
    "    summaries.append(summary_text)\n",
    "\n",
    "# Join the summaries back together into a single summary\n",
    "final_summary = ' '.join(summaries)\n",
    "\n",
    "print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408aef07-a191-401e-96a6-0f04fa683abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, max_chunk_size):\n",
    "    return textwrap.wrap(text, max_chunk_size)\n",
    "\n",
    "client = OpenAI(api_key =os.environ['..\\\\.venv\\\\secrets\\\\OPENAI_API_KEY'])\n",
    "#openai.api_key = \"OPENAI_API_KEY\" removed per https://github.com/openai/openai-python/discussions/742\n",
    "max_chunk_size = 4000\n",
    "\n",
    "transcript_chunks = split_text_into_chunks(transcript_text, max_chunk_size)\n",
    "summaries = \"\"\n",
    "\n",
    "for chunk in transcript_chunks:\n",
    "    #Remove response = openai.ChatCompletion.create per https://github.com/openai/openai-python/discussions/742\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        prompt=\"You are a helpful assistant.\\n\\nUser: \" + chunk + \"\\n\\nCreate short concise summary:\",\n",
    "        #messages=[\n",
    "            #{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            #{\"role\": \"user\", \"content\": f\"{chunk}\\n\\nCreate short concise summary\"}\n",
    "        #],\n",
    "        max_tokens=250,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    summaries += response['choices'][0]['message']['content'].strip() + \" \"\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f4267-3a5a-4bf0-ae57-48c1b79e3c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo-16k\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a technical instructor.\"},\n",
    "{\"role\": \"user\", \"content\": transcript_text},\n",
    "{\"role\": \"user\", \"content\": \"Generate steps to follow from text.\"},\n",
    "]\n",
    ")\n",
    "\n",
    "# The assistant's reply\n",
    "guide= response['choices'][0]['message']['content']\n",
    "\n",
    "print(\"Steps:\")\n",
    "print(guide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1baf718-84cf-4720-9660-02882201c262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo-16k\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant that generates questions.\"},\n",
    "{\"role\": \"user\", \"content\": transcript_text},\n",
    "{\"role\": \"user\", \"content\": \"Generate 65 quiz questions based on the text with multiple choices.\"},\n",
    "]\n",
    ")\n",
    "\n",
    "# The assistant's reply\n",
    "quiz_questions = response['choices'][0]['message']['content']\n",
    "\n",
    "print(\"Quiz Questions:\")\n",
    "print(quiz_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e4d89-6205-4b48-9b56-21be7449c089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
