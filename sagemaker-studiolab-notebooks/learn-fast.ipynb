{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa277843-0bc3-4179-853b-a5b473ad9653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import torch\n",
    "import torchaudio\n",
    "import openai\n",
    "import textwrap\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918dfc7-91e8-4ff7-bd9e-58f674275f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the YouTube video URL\n",
    "youtube_url = \"\"\n",
    "\n",
    "# Extract the video ID from the URL using regular expressions\n",
    "match = re.search(r\"v=([A-Za-z0-9_-]+)\", youtube_url)\n",
    "if match:\n",
    "    video_id = match.group(1)\n",
    "else:\n",
    "    raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "# Get the transcript from YouTube\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "# Concatenate the transcript into a single string\n",
    "transcript_text = \"\"\n",
    "for segment in transcript:\n",
    "    transcript_text += segment[\"text\"] + \" \"\n",
    "print(transcript_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdfc62-1187-464c-a7d2-cf21594c5e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_length = 512\n",
    "\n",
    "# Split the input text into smaller segments\n",
    "segments = [transcript_text[i:i+max_length] for i in range(0, len(transcript_text), max_length)]\n",
    "\n",
    "# Translate each segment and concatenate the results\n",
    "translated_text = \"\"\n",
    "for segment in segments:\n",
    "    result = translator(segment)\n",
    "    translated_text += result[0]['translation_text']\n",
    "\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50374a98-eab9-488b-8c2e-b8ec32d2d1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# Instantiate the tokenizer and the summarization pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained('stevhliu/my_awesome_billsum_model')\n",
    "summarizer = pipeline(\"summarization\", model='stevhliu/my_awesome_billsum_model', tokenizer=tokenizer)\n",
    "\n",
    "# Define chunk size in number of words\n",
    "chunk_size = 200 # you may need to adjust this value depending on the average length of your words\n",
    "\n",
    "# Split the text into chunks\n",
    "words = transcript_text.split()\n",
    "chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# Summarize each chunk\n",
    "summaries = []\n",
    "for chunk in chunks:\n",
    "    # Summarize the chunk\n",
    "    summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)\n",
    "\n",
    "    # Extract the summary text\n",
    "    summary_text = summary[0]['summary_text']\n",
    "\n",
    "    # Add the summary to our list of summaries\n",
    "    summaries.append(summary_text)\n",
    "\n",
    "# Join the summaries back together into a single summary\n",
    "final_summary = ' '.join(summaries)\n",
    "\n",
    "print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408aef07-a191-401e-96a6-0f04fa683abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, max_chunk_size):\n",
    "    return textwrap.wrap(text, max_chunk_size)\n",
    "\n",
    "openai.api_key = \"\"\n",
    "max_chunk_size = 4000\n",
    "\n",
    "transcript_chunks = split_text_into_chunks(transcript_text, max_chunk_size)\n",
    "summaries = \"\"\n",
    "\n",
    "for chunk in transcript_chunks:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{chunk}\\n\\nCreate short concise summary\"}\n",
    "        ],\n",
    "        max_tokens=250,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    summaries += response['choices'][0]['message']['content'].strip() + \" \"\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f4267-3a5a-4bf0-ae57-48c1b79e3c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo-16k\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a technical instructor.\"},\n",
    "{\"role\": \"user\", \"content\": transcript_text},\n",
    "{\"role\": \"user\", \"content\": \"Generate steps to follow from text.\"},\n",
    "]\n",
    ")\n",
    "\n",
    "# The assistant's reply\n",
    "guide= response['choices'][0]['message']['content']\n",
    "\n",
    "print(\"Steps:\")\n",
    "print(guide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1baf718-84cf-4720-9660-02882201c262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo-16k\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant that generates questions.\"},\n",
    "{\"role\": \"user\", \"content\": transcript_text},\n",
    "{\"role\": \"user\", \"content\": \"Generate 65 quiz questions based on the text with multiple choices.\"},\n",
    "]\n",
    ")\n",
    "\n",
    "# The assistant's reply\n",
    "quiz_questions = response['choices'][0]['message']['content']\n",
    "\n",
    "print(\"Quiz Questions:\")\n",
    "print(quiz_questions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
